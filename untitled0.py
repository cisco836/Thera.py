# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16RBUhMdNRhxcJDFwOJcF02VhQg5lY7Ax
"""

import os
from keras.preprocessing import sequence
import tensorflow as tf
import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.preprocessing.text import Tokenizer
from sklearn.model_selection import train_test_split
from keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical
from keras.callbacks import EarlyStopping
from keras.layers import Dropout
import random
import googletrans
from googletrans import Translator

df = pd.read_csv("./20200325_counsel_chat.csv", encoding='utf-8')
df.head()


# Number of counselors
df.groupby("therapistURL").agg("count").shape

# Number of Topics
len(set(df["topic"].tolist()))

# Number of responses
df.shape

# Number of questions
len(set(df["questionLink"].tolist()))

# Average number of responses to questions
df.groupby("questionLink").agg("count").describe()

df["has_upvote"] = df["upvotes"].apply(lambda x: 1 if int(x) > 0 else 0)
df["has_upvote"].sum() / df.shape[0]
x_train = df[df["split"] == "train"]
y_train = x_train["has_upvote"]
x_val = df[df["split"] == "val"]
y_val = x_val["has_upvote"]

x_train["has_upvote"]



# The maximum number of words to be used. (most frequent)
MAX_NB_WORDS = 50000
# Max number of words in each question.
MAX_SEQUENCE_LENGTH = 600
# This is fixed.
EMBEDDING_DIM = 100
texts = df['questionText'].values
tokenizer = Tokenizer()
tokenizer.fit_on_texts(texts)
X = tokenizer.texts_to_sequences(texts)
X = tf.keras.preprocessing.sequence.pad_sequences(X, MAX_SEQUENCE_LENGTH)
print('Shape of data tensor:', X.shape)

x_train["questionText"]

#get max length of string
pd.columns = ["questionText"]

length_of_the_messages = x_train["questionText"].str.split("\\s+")

print(length_of_the_messages)
print("Max number of words = ", length_of_the_messages.str.len().max())
print("Index = ", length_of_the_messages.str.len().idxmax())

x_train["questionText"][815]

Y = pd.get_dummies(df['topic']).values
print('Shape of label tensor:', Y.shape)


X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.10, random_state=42)
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

model = Sequential()
model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model.add(SpatialDropout1D(0.2))
model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(31, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer='adam', metrics=['accuracy'])
print(model.summary())




# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

history = model.fit(X_train, Y_train, epochs=10,batch_size=64, validation_split=0.1)

plt.title('Accuracy')
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='test')
plt.legend()
plt.show();

textofpatient = ["I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it."]
seq = tokenizer.texts_to_sequences(textofpatient)
padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)
pred = model.predict(padded)
labels = df["topic"].unique()
print(labels)
print(pred, labels[np.argmax(pred)])

model.save("therapy_model_detect_disease.h5",save_format='h5')

from keras.models import load_model
loaded_2 =load_model("/content/therapy_model_detect_disease")

def prediction(text="What if I can't do it?"):
  textofpatient = [text]
  seq = tokenizer.texts_to_sequences(textofpatient)
  padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)
  pred = model.predict(padded)
  labels = df["topic"].unique()
  return labels[np.argmax(pred)]

print(prediction())

# !pwd
# !zip -r /content/therapy_model_detect_disease.zip /content/therapy_model_detect_disease
# from google.colab import files

# files.download("/content/therapy_model_detect_disease.h5")

# !unzip /therapy_model_detect_disease.zip

# !cd ..

# !pip install tensorflowjs

# import tensorflowjs as tfjs
# tfjs.converters.save_keras_model(loaded_2, "model_js_therapy")
# !ls

# !pwd

# !zip -r /content/model_js_therapy.zip /content/model_js_therapy

# from google.colab import files
# files.download("/content/model_js_therapy.zip")

# !pip3 install --user Flask

